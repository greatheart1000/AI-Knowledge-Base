#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LangGraph é«˜çº§è®°å¿†ç³»ç»Ÿ
å®ç°ç”Ÿäº§çº§çš„é•¿çŸ­æœŸè®°å¿†ã€RAGã€å¤æ‚å¯¹è¯åœºæ™¯ç®¡ç†
"""

import os
import sys
import json
import time
import uuid
import asyncio
from typing import TypedDict, List, Dict, Any, Optional, Union
from dataclasses import dataclass, field
from datetime import datetime, timezone, timedelta
from enum import Enum
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore
from langgraph.runtime import Runtime
from langchain_core.embeddings import Embeddings
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage


# ==================== é…ç½®å’Œæšä¸¾ ====================

class MemoryType(Enum):
    """è®°å¿†ç±»å‹"""
    SHORT_TERM = "short_term"
    LONG_TERM = "long_term"
    EPISODIC = "episodic"  # æƒ…èŠ‚è®°å¿†
    SEMANTIC = "semantic"  # è¯­ä¹‰è®°å¿†
    PROCEDURAL = "procedural"  # ç¨‹åºè®°å¿†


class ImportanceLevel(Enum):
    """é‡è¦æ€§çº§åˆ«"""
    LOW = 0.3
    MEDIUM = 0.6
    HIGH = 0.8
    CRITICAL = 1.0


@dataclass
class MemoryConfig:
    """è®°å¿†é…ç½®"""
    max_short_term_size: int = 20
    max_long_term_size: int = 1000
    importance_threshold: float = 0.7
    decay_factor: float = 0.95
    consolidation_interval: int = 10  # æ¯10è½®å¯¹è¯è¿›è¡Œä¸€æ¬¡è®°å¿†æ•´åˆ


# ==================== è®°å¿†æ•°æ®ç»“æ„ ====================

@dataclass
class MemoryItem:
    """è®°å¿†é¡¹"""
    id: str
    content: str
    memory_type: MemoryType
    importance: float
    timestamp: datetime
    access_count: int = 0
    last_accessed: Optional[datetime] = None
    tags: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "id": self.id,
            "content": self.content,
            "memory_type": self.memory_type.value,
            "importance": self.importance,
            "timestamp": self.timestamp.isoformat(),
            "access_count": self.access_count,
            "last_accessed": self.last_accessed.isoformat() if self.last_accessed else None,
            "tags": self.tags,
            "metadata": self.metadata
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'MemoryItem':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(
            id=data["id"],
            content=data["content"],
            memory_type=MemoryType(data["memory_type"]),
            importance=data["importance"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            access_count=data.get("access_count", 0),
            last_accessed=datetime.fromisoformat(data["last_accessed"]) if data.get("last_accessed") else None,
            tags=data.get("tags", []),
            metadata=data.get("metadata", {})
        )


@dataclass
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡"""
    user_id: str
    session_id: str
    thread_id: str
    current_topic: str = ""
    conversation_goals: List[str] = field(default_factory=list)
    user_preferences: Dict[str, Any] = field(default_factory=dict)
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    active_memories: List[str] = field(default_factory=list)  # å½“å‰æ¿€æ´»çš„è®°å¿†ID


# ==================== é«˜çº§è®°å¿†ç®¡ç†å™¨ ====================

class AdvancedMemoryManager:
    """é«˜çº§è®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, store: InMemoryStore, config: MemoryConfig = None):
        self.store = store
        self.config = config or MemoryConfig()
        self.memory_cache: Dict[str, MemoryItem] = {}
        self.access_patterns: Dict[str, List[datetime]] = {}
        
    def add_memory(self, 
                   user_id: str, 
                   content: str, 
                   memory_type: MemoryType,
                   importance: float = 0.5,
                   tags: List[str] = None,
                   metadata: Dict[str, Any] = None) -> str:
        """æ·»åŠ è®°å¿†"""
        memory_id = str(uuid.uuid4())
        
        memory_item = MemoryItem(
            id=memory_id,
            content=content,
            memory_type=memory_type,
            importance=importance,
            timestamp=datetime.now(timezone.utc),
            tags=tags or [],
            metadata=metadata or {}
        )
        
        # å­˜å‚¨åˆ°ç¼“å­˜å’ŒæŒä¹…åŒ–å­˜å‚¨
        self.memory_cache[memory_id] = memory_item
        self.store.put(
            ("memories", user_id, memory_type.value),
            memory_id,
            memory_item.to_dict()
        )
        
        return memory_id
    
    def retrieve_memories(self, 
                         user_id: str, 
                         query: str = "",
                         memory_types: List[MemoryType] = None,
                         limit: int = 10,
                         min_importance: float = 0.0) -> List[MemoryItem]:
        """æ£€ç´¢è®°å¿†"""
        memories = []
        
        # ä»å­˜å‚¨ä¸­æœç´¢
        for memory_type in (memory_types or list(MemoryType)):
            results = self.store.search(
                ("memories", user_id, memory_type.value),
                query=query,
                limit=limit
            )
            
            for result in results:
                memory_data = result.value
                if memory_data["importance"] >= min_importance:
                    memory_item = MemoryItem.from_dict(memory_data)
                    memories.append(memory_item)
        
        # æŒ‰é‡è¦æ€§å’Œæ—¶é—´æ’åº
        memories.sort(key=lambda x: (x.importance, x.timestamp), reverse=True)
        return memories[:limit]
    
    def update_memory_access(self, memory_id: str):
        """æ›´æ–°è®°å¿†è®¿é—®è®°å½•"""
        if memory_id in self.memory_cache:
            memory = self.memory_cache[memory_id]
            memory.access_count += 1
            memory.last_accessed = datetime.now(timezone.utc)
            
            # æ›´æ–°è®¿é—®æ¨¡å¼
            if memory_id not in self.access_patterns:
                self.access_patterns[memory_id] = []
            self.access_patterns[memory_id].append(datetime.now(timezone.utc))
    
    def consolidate_memories(self, user_id: str) -> Dict[str, Any]:
        """è®°å¿†æ•´åˆ - å°†çŸ­æœŸè®°å¿†æ•´åˆåˆ°é•¿æœŸè®°å¿†"""
        consolidation_report = {
            "promoted_memories": 0,
            "decayed_memories": 0,
            "consolidated_at": datetime.now(timezone.utc).isoformat()
        }
        
        # è·å–æ‰€æœ‰çŸ­æœŸè®°å¿†
        short_term_memories = self.retrieve_memories(
            user_id, 
            memory_types=[MemoryType.SHORT_TERM],
            limit=100
        )
        
        for memory in short_term_memories:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æå‡åˆ°é•¿æœŸè®°å¿†
            if (memory.importance >= self.config.importance_threshold and 
                memory.access_count >= 3):
                
                # æå‡åˆ°é•¿æœŸè®°å¿†
                self.add_memory(
                    user_id,
                    memory.content,
                    MemoryType.LONG_TERM,
                    memory.importance,
                    memory.tags,
                    {**memory.metadata, "promoted_from": memory.id}
                )
                consolidation_report["promoted_memories"] += 1
                
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¡°å‡
            elif (memory.importance < 0.3 and 
                  memory.last_accessed and 
                  datetime.now(timezone.utc) - memory.last_accessed > timedelta(days=7)):
                
                # è¡°å‡è®°å¿†é‡è¦æ€§
                memory.importance *= self.config.decay_factor
                if memory.importance < 0.1:
                    # åˆ é™¤ä½é‡è¦æ€§è®°å¿†
                    self.store.put(
                        ("memories", user_id, MemoryType.SHORT_TERM.value),
                        memory.id,
                        None  # åˆ é™¤
                    )
                    consolidation_report["decayed_memories"] += 1
        
        return consolidation_report


# ==================== æ™ºèƒ½è®°å¿†åˆ†æå™¨ ====================

class MemoryAnalyzer:
    """è®°å¿†åˆ†æå™¨"""
    
    def __init__(self):
        self.keyword_patterns = {
            "preference": ["å–œæ¬¢", "åå¥½", "ä¹ æƒ¯", "prefer", "like"],
            "fact": ["æ˜¯", "æœ‰", "åœ¨", "is", "has", "was"],
            "goal": ["æƒ³è¦", "å¸Œæœ›", "éœ€è¦", "want", "need", "goal"],
            "emotion": ["é«˜å…´", "éš¾è¿‡", "ç”Ÿæ°”", "happy", "sad", "angry"],
            "important": ["é‡è¦", "å…³é”®", "è®°ä½", "important", "critical", "remember"]
        }
    
    def analyze_content(self, content: str) -> Dict[str, Any]:
        """åˆ†æå†…å®¹"""
        analysis = {
            "memory_type": MemoryType.SHORT_TERM,
            "importance": 0.5,
            "tags": [],
            "metadata": {}
        }
        
        content_lower = content.lower()
        
        # åˆ†æè®°å¿†ç±»å‹
        if any(keyword in content_lower for keyword in self.keyword_patterns["preference"]):
            analysis["memory_type"] = MemoryType.LONG_TERM
            analysis["tags"].append("preference")
        
        if any(keyword in content_lower for keyword in self.keyword_patterns["fact"]):
            analysis["memory_type"] = MemoryType.SEMANTIC
            analysis["tags"].append("fact")
        
        if any(keyword in content_lower for keyword in self.keyword_patterns["goal"]):
            analysis["memory_type"] = MemoryType.EPISODIC
            analysis["tags"].append("goal")
        
        # åˆ†æé‡è¦æ€§
        if any(keyword in content_lower for keyword in self.keyword_patterns["important"]):
            analysis["importance"] = 0.9
        elif any(keyword in content_lower for keyword in self.keyword_patterns["emotion"]):
            analysis["importance"] = 0.7
        elif len(content) > 100:  # é•¿å†…å®¹é€šå¸¸æ›´é‡è¦
            analysis["importance"] = 0.6
        
        # æå–å…ƒæ•°æ®
        analysis["metadata"] = {
            "content_length": len(content),
            "word_count": len(content.split()),
            "has_question": "?" in content,
            "has_exclamation": "!" in content
        }
        
        return analysis


# ==================== çŠ¶æ€å®šä¹‰ ====================

class AdvancedConversationState(TypedDict):
    """é«˜çº§å¯¹è¯çŠ¶æ€"""
    messages: List[Dict[str, Any]]
    context: ConversationContext
    active_memories: List[Dict[str, Any]]  # å­˜å‚¨åºåˆ—åŒ–çš„è®°å¿†æ•°æ®
    memory_summary: str
    conversation_goals: List[str]
    user_preferences: Dict[str, Any]
    processing_metadata: Dict[str, Any]


# ==================== å›¾èŠ‚ç‚¹å®ç° ====================

def create_advanced_memory_graph():
    """åˆ›å»ºé«˜çº§è®°å¿†å›¾"""
    
    # åˆ›å»ºå…¨å±€è®°å¿†ç®¡ç†å™¨å’Œåˆ†æå™¨å®ä¾‹
    global_memory_manager = None
    global_memory_analyzer = MemoryAnalyzer()
    
    def memory_analysis_node(state: AdvancedConversationState, runtime: Runtime[ConversationContext]) -> AdvancedConversationState:
        """è®°å¿†åˆ†æèŠ‚ç‚¹"""
        nonlocal global_memory_manager
        
        context = runtime.context
        current_message = state["messages"][-1] if state["messages"] else {}
        content = current_message.get('content', '')
        
        # åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨ - ä½¿ç”¨å…¨å±€å®ä¾‹é¿å…åºåˆ—åŒ–é—®é¢˜
        if global_memory_manager is None:
            global_memory_manager = AdvancedMemoryManager(runtime.store)
        
        # åˆ†æå†…å®¹
        analysis = global_memory_analyzer.analyze_content(content)
        
        # æ·»åŠ è®°å¿†
        memory_id = global_memory_manager.add_memory(
            user_id=context.user_id,
            content=content,
            memory_type=analysis["memory_type"],
            importance=analysis["importance"],
            tags=analysis["tags"],
            metadata=analysis["metadata"]
        )
        
        # æ›´æ–°çŠ¶æ€ - åªå­˜å‚¨å¯åºåˆ—åŒ–çš„æ•°æ®
        state["processing_metadata"]["memory_analysis"] = analysis
        state["processing_metadata"]["memory_id"] = memory_id
        
        return state
    
    def memory_retrieval_node(state: AdvancedConversationState, runtime: Runtime[ConversationContext]) -> AdvancedConversationState:
        """è®°å¿†æ£€ç´¢èŠ‚ç‚¹"""
        nonlocal global_memory_manager
        
        context = runtime.context
        current_message = state["messages"][-1] if state["messages"] else {}
        query = current_message.get('content', '')
        
        # ç¡®ä¿è®°å¿†ç®¡ç†å™¨å·²åˆå§‹åŒ–
        if global_memory_manager is None:
            global_memory_manager = AdvancedMemoryManager(runtime.store)
        
        # æ£€ç´¢ç›¸å…³è®°å¿†
        relevant_memories = global_memory_manager.retrieve_memories(
            user_id=context.user_id,
            query=query,
            limit=5,
            min_importance=0.3
        )
        
        # æ›´æ–°è®¿é—®è®°å½•
        for memory in relevant_memories:
            global_memory_manager.update_memory_access(memory.id)
        
        # æ›´æ–°çŠ¶æ€ - å°†MemoryItemå¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
        state["active_memories"] = [memory.to_dict() for memory in relevant_memories]
        state["context"].active_memories = [m["id"] for m in state["active_memories"]]
        
        return state
    
    def intelligent_response_node(state: AdvancedConversationState, runtime: Runtime[ConversationContext]) -> AdvancedConversationState:
        """æ™ºèƒ½å“åº”èŠ‚ç‚¹"""
        current_message = state["messages"][-1] if state["messages"] else {}
        active_memories = state["active_memories"]
        
        # æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡ - å¤„ç†åºåˆ—åŒ–çš„è®°å¿†æ•°æ®
        memory_context = []
        for memory_dict in active_memories:
            memory_type = memory_dict.get("memory_type", "unknown")
            content = memory_dict.get("content", "")
            memory_context.append(f"[{memory_type}] {content[:50]}...")
        
        # ç”Ÿæˆæ™ºèƒ½å“åº”
        response_content = f"æ™ºèƒ½å›å¤: {current_message.get('content', '')}"
        
        if memory_context:
            response_content += f"\n[ç›¸å…³è®°å¿†: {'; '.join(memory_context)}]"
        
        # æ·»åŠ è®°å¿†æ‘˜è¦
        if len(state["messages"]) > 5:
            recent_topics = [msg.get('content', '')[:20] for msg in state["messages"][-5:]]
            state["memory_summary"] = f"æœ€è¿‘è¯é¢˜: {', '.join(recent_topics)}"
        
        # æ·»åŠ å“åº”æ¶ˆæ¯
        state["messages"].append({
            "role": "assistant",
            "content": response_content,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "memory_context": memory_context
        })
        
        return state
    
    def memory_consolidation_node(state: AdvancedConversationState, runtime: Runtime[ConversationContext]) -> AdvancedConversationState:
        """è®°å¿†æ•´åˆèŠ‚ç‚¹"""
        nonlocal global_memory_manager
        
        context = runtime.context
        
        # ç¡®ä¿è®°å¿†ç®¡ç†å™¨å·²åˆå§‹åŒ–
        if global_memory_manager is None:
            global_memory_manager = AdvancedMemoryManager(runtime.store)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ•´åˆè®°å¿†
        message_count = len(state["messages"])
        if message_count % global_memory_manager.config.consolidation_interval == 0:
            consolidation_report = global_memory_manager.consolidate_memories(context.user_id)
            state["processing_metadata"]["consolidation_report"] = consolidation_report
        
        return state
    
    # åˆ›å»ºå›¾
    graph = StateGraph(state_schema=AdvancedConversationState)
    graph.add_node("memory_analysis", memory_analysis_node)
    graph.add_node("memory_retrieval", memory_retrieval_node)
    graph.add_node("intelligent_response", intelligent_response_node)
    graph.add_node("memory_consolidation", memory_consolidation_node)
    
    graph.set_entry_point("memory_analysis")
    graph.add_edge("memory_analysis", "memory_retrieval")
    graph.add_edge("memory_retrieval", "intelligent_response")
    graph.add_edge("intelligent_response", "memory_consolidation")
    graph.add_edge("memory_consolidation", END)
    
    return graph


# ==================== æ¼”ç¤ºå‡½æ•° ====================

def demo_advanced_memory_system():
    """æ¼”ç¤ºé«˜çº§è®°å¿†ç³»ç»Ÿ"""
    print("ğŸ§  é«˜çº§è®°å¿†ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºå­˜å‚¨å’Œæ£€æŸ¥ç‚¹
    store = InMemoryStore()
    checkpointer = InMemorySaver()
    
    # åˆ›å»ºå›¾
    graph = create_advanced_memory_graph()
    compiled_graph = graph.compile(store=store, checkpointer=checkpointer)
    
    # åˆ›å»ºç”¨æˆ·ä¸Šä¸‹æ–‡
    user_context = ConversationContext(
        user_id="advanced_user_001",
        session_id=str(uuid.uuid4()),
        thread_id="advanced_thread_001",
        current_topic="AIæŠ€æœ¯è®¨è®º",
        conversation_goals=["å­¦ä¹ LangGraph", "äº†è§£è®°å¿†æœºåˆ¶"],
        user_preferences={"language": "zh", "detail_level": "high"}
    )
    
    # æ¨¡æ‹Ÿå¤æ‚å¯¹è¯åœºæ™¯
    conversation_scenarios = [
        {
            "message": "æˆ‘å–œæ¬¢å–å’–å•¡ï¼Œç‰¹åˆ«æ˜¯æ‹¿é“ï¼Œæ¯å¤©éƒ½è¦å–ä¸¤æ¯",
            "expected_type": "preference",
            "expected_importance": "high"
        },
        {
            "message": "æˆ‘çš„ç”Ÿæ—¥æ˜¯12æœˆ25æ—¥ï¼Œè¯·è®°ä½è¿™ä¸ªé‡è¦æ—¥æœŸ",
            "expected_type": "fact",
            "expected_importance": "critical"
        },
        {
            "message": "æˆ‘æƒ³è¦å­¦ä¹ æ›´å¤šå…³äºäººå·¥æ™ºèƒ½çš„çŸ¥è¯†",
            "expected_type": "goal",
            "expected_importance": "medium"
        },
        {
            "message": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "expected_type": "episodic",
            "expected_importance": "low"
        },
        {
            "message": "è¯·å‘Šè¯‰æˆ‘å…³äºè®°å¿†æœºåˆ¶çš„ä¿¡æ¯",
            "expected_type": "semantic",
            "expected_importance": "medium"
        }
    ]
    
    for i, scenario in enumerate(conversation_scenarios):
        print(f"\nç¬¬ {i+1} è½®å¯¹è¯:")
        print(f"åœºæ™¯: {scenario['message']}")
        
        # åˆ›å»ºçŠ¶æ€
        state = AdvancedConversationState(
            messages=[{
                "role": "user",
                "content": scenario["message"],
                "timestamp": datetime.now(timezone.utc).isoformat()
            }],
            context=user_context,
            active_memories=[],
            memory_summary="",
            conversation_goals=[],
            user_preferences={},
            processing_metadata={}
        )
        
        # è¿è¡Œå›¾
        result = compiled_graph.invoke(
            state,
            config={"configurable": {"thread_id": user_context.thread_id}},
            context=user_context
        )
        
        print(f"ç”¨æˆ·: {scenario['message']}")
        print(f"åŠ©æ‰‹: {result['messages'][-1]['content']}")
        
        # æ˜¾ç¤ºè®°å¿†åˆ†æç»“æœ
        if result["processing_metadata"].get("memory_analysis"):
            analysis = result["processing_metadata"]["memory_analysis"]
            print(f"è®°å¿†åˆ†æ: ç±»å‹={analysis['memory_type'].value}, é‡è¦æ€§={analysis['importance']:.2f}")
            print(f"æ ‡ç­¾: {analysis['tags']}")
        
        # æ˜¾ç¤ºæ¿€æ´»çš„è®°å¿†
        if result["active_memories"]:
            print("æ¿€æ´»çš„è®°å¿†:")
            for memory_dict in result["active_memories"]:
                memory_type = memory_dict.get("memory_type", "unknown")
                content = memory_dict.get("content", "")
                importance = memory_dict.get("importance", 0.0)
                print(f"  - [{memory_type}] {content[:40]}... (é‡è¦æ€§: {importance:.2f})")
        
        # æ˜¾ç¤ºæ•´åˆæŠ¥å‘Š
        if result["processing_metadata"].get("consolidation_report"):
            report = result["processing_metadata"]["consolidation_report"]
            print(f"è®°å¿†æ•´åˆ: æå‡={report['promoted_memories']}, è¡°å‡={report['decayed_memories']}")
        
        print("-" * 50)


def demo_memory_consolidation():
    """æ¼”ç¤ºè®°å¿†æ•´åˆè¿‡ç¨‹"""
    print("\nğŸ”„ è®°å¿†æ•´åˆæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºè®°å¿†ç®¡ç†å™¨
    store = InMemoryStore()
    memory_manager = AdvancedMemoryManager(store)
    
    user_id = "consolidation_user"
    
    # æ·»åŠ ä¸åŒç±»å‹çš„è®°å¿†
    memories_to_add = [
        ("æˆ‘å–œæ¬¢å–å’–å•¡", MemoryType.SHORT_TERM, 0.8),
        ("æˆ‘çš„åå­—æ˜¯å¼ ä¸‰", MemoryType.SHORT_TERM, 0.9),
        ("ä»Šå¤©å¤©æ°”å¾ˆå¥½", MemoryType.SHORT_TERM, 0.3),
        ("æˆ‘æ˜¯ä¸€åç¨‹åºå‘˜", MemoryType.SHORT_TERM, 0.7),
        ("æ˜å¤©æœ‰ä¼šè®®", MemoryType.SHORT_TERM, 0.6),
    ]
    
    print("æ·»åŠ åˆå§‹è®°å¿†:")
    for content, memory_type, importance in memories_to_add:
        memory_id = memory_manager.add_memory(user_id, content, memory_type, importance)
        print(f"  - {content} (é‡è¦æ€§: {importance})")
    
    # æ¨¡æ‹Ÿè®¿é—®æ¨¡å¼
    print("\næ¨¡æ‹Ÿè®°å¿†è®¿é—®:")
    all_memories = memory_manager.retrieve_memories(user_id, limit=10)
    for memory in all_memories[:3]:  # è®¿é—®å‰3ä¸ªè®°å¿†
        for _ in range(5):  # æ¯ä¸ªè®°å¿†è®¿é—®5æ¬¡
            memory_manager.update_memory_access(memory.id)
        print(f"  - è®¿é—®è®°å¿†: {memory.content} (è®¿é—®æ¬¡æ•°: {memory.access_count})")
    
    # æ‰§è¡Œè®°å¿†æ•´åˆ
    print("\næ‰§è¡Œè®°å¿†æ•´åˆ:")
    consolidation_report = memory_manager.consolidate_memories(user_id)
    print(f"æ•´åˆæŠ¥å‘Š: {consolidation_report}")
    
    # æ˜¾ç¤ºæ•´åˆåçš„è®°å¿†çŠ¶æ€
    print("\næ•´åˆåçš„è®°å¿†çŠ¶æ€:")
    final_memories = memory_manager.retrieve_memories(user_id, limit=10)
    for memory in final_memories:
        print(f"  - [{memory.memory_type.value}] {memory.content} (é‡è¦æ€§: {memory.importance:.2f}, è®¿é—®: {memory.access_count})")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LangGraph é«˜çº§è®°å¿†ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    try:
        # è¿è¡Œæ¼”ç¤º
        demo_advanced_memory_system()
        demo_memory_consolidation()
        
        print("\nğŸ‰ é«˜çº§è®°å¿†ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ é«˜çº§ç‰¹æ€§æ€»ç»“:")
        print("1. æ™ºèƒ½è®°å¿†åˆ†æ: è‡ªåŠ¨è¯†åˆ«è®°å¿†ç±»å‹å’Œé‡è¦æ€§")
        print("2. åˆ†å±‚è®°å¿†ç®¡ç†: çŸ­æœŸã€é•¿æœŸã€æƒ…èŠ‚ã€è¯­ä¹‰ã€ç¨‹åºè®°å¿†")
        print("3. è®°å¿†æ•´åˆæœºåˆ¶: è‡ªåŠ¨æå‡é‡è¦è®°å¿†ï¼Œè¡°å‡æ— ç”¨è®°å¿†")
        print("4. è®¿é—®æ¨¡å¼è·Ÿè¸ª: è®°å½•è®°å¿†ä½¿ç”¨é¢‘ç‡å’Œæ¨¡å¼")
        print("5. ä¸Šä¸‹æ–‡æ„ŸçŸ¥: åŸºäºå¯¹è¯ä¸Šä¸‹æ–‡æ™ºèƒ½æ£€ç´¢ç›¸å…³è®°å¿†")
        print("6. ç”Ÿäº§çº§æ¶æ„: æ”¯æŒå¤§è§„æ¨¡éƒ¨ç½²å’ŒæŒä¹…åŒ–å­˜å‚¨")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
